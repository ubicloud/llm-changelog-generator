[
  {
    "pr": 3375,
    "title": "Handle Aws::S3::Errors::ServiceUnavailable during multipart upload",
    "description": "Treat this as a 503 error and not a 400 errors, because it is not an issue with the request.\n\nFixes an unhandled production exception.",
    "ellipsis_summary": "Handle `Aws::S3::Errors::ServiceUnavailable` as a 503 error during multipart uploads in `routes/runtime/github.rb`.\n> \n>   - **Error Handling**:\n>     - In `routes/runtime/github.rb`, handle `Aws::S3::Errors::ServiceUnavailable` during multipart upload by logging the error and returning a 503 status code.\n>   - **Tests**:\n>     - Add test in `github_spec.rb` to verify 503 error handling when S3 service is unavailable during multipart upload.\n> \n>"
  },
  {
    "pr": 3389,
    "title": "First phase of route cleanup",
    "description": "Most of these are fairly simple route restructuring changes, best viewed ignored whitespace differences. There a a couple that change queries to be more efficient.",
    "ellipsis_summary": "Refactored and optimized route handling across multiple files for improved organization and efficiency, including query optimizations and test updates.\n> \n>   - **Route Restructuring**:\n>     - Consolidated `r.get` and `r.post` blocks under `r.is` in `project.rb`, `billing.rb`, `discount_code.rb`, `inference_api_key.rb`, `kubernetes_cluster.rb`, `firewall.rb`, `firewall_rule.rb`, `load_balancer.rb`, `postgres.rb`, `private_subnet.rb`, `private_location.rb`, `token.rb`, `usage_alert.rb`, `user.rb`, and `github.rb`.\n>     - Changed `r.delete true` to `r.delete` in `billing.rb`, `firewall.rb`, `firewall_rule.rb`, `load_balancer.rb`, `postgres.rb`, `private_subnet.rb`, `token.rb`, `usage_alert.rb`, and `user.rb`.\n>     - Replaced `r.get true` with `r.get` in `project.rb`, `billing.rb`, `firewall.rb`, `load_balancer.rb`, `postgres.rb`, `private_subnet.rb`, `private_location.rb`, `user.rb`, and `github.rb`.\n>   - **Query Optimization**:\n>     - Improved query efficiency in `billing.rb` by using `unless ... empty?` instead of `select_map.include?` for fraud check.\n>     - Optimized dataset filtering in `github.rb` for cache entries.\n>   - **Miscellaneous**:\n>     - Updated test cases in `access_control_spec.rb` and `billing_spec.rb` to reflect route changes.\n>     - Minor refactoring and cleanup in various route files for consistency and readability.\n> \n>"
  },
  {
    "pr": 3407,
    "title": "Collect VmHost node_exporter metrics and store in VictoriaMetrics",
    "description": "New logic is added to VmHost model to serve metrics config to start collecting node_exporter metrics on the VmHosts.\n\nAlso a new label is added to the VmHost prog to install the right scripts to collect the metrics from the node_exporter in the right directory for bin/monitor to collect",
    "ellipsis_summary": "Add functionality to collect and store VmHost node_exporter metrics in VictoriaMetrics, including configuration and setup for Grafana.\n> \n>   - **Behavior**:\n>     - Add `VmHost` to `metrics_target_resource_types` in `bin/monitor` to collect node_exporter metrics.\n>     - New method `metrics_config` in `VmHost` to define metrics collection configuration.\n>     - New `configure_metrics` label in `host_nexus.rb` to set up metrics collection service and timer.\n>   - **Configuration**:\n>     - Add `monitoring_service_project_id` to `config.rb` for metrics configuration.\n>   - **Setup**:\n>     - New `Prog::SetupGrafana` class and `setup-grafana` script to install and configure Grafana.\n>   - **Testing**:\n>     - Add tests for `metrics_config` in `vm_host_spec.rb`.\n>     - Add tests for `SetupGrafana` in `setup_grafana_spec.rb`.\n>     - Add tests for `configure_metrics` in `host_nexus_spec.rb`.\n> \n>"
  },
  {
    "pr": 3416,
    "title": "Add grafana installation strand",
    "description": "This strand will try to install grafana on the provided subject id. The strand won't create the vm or add the DNS records but takes care of all the remaining logics which must be run inside the vm like installing the nginx, certbot, getting the certificate and installing the grafana.\n\nThe API looks like this:\n\nvm = Prog::Vm::Nexus.assemble_with_sshable(project_id,\n  sshable_unix_user: \"ubi\", name: \"grafana-0\", enable_ip4: true).subject\n\nAt this step create an A record, resolving your domain to the vm ip.\n\nStrand.create(prog: \"SetupGrafana\", label: \"start\", stack:\n  [{subject_id: vm.id, domain: \"grafana.domain.com\",\n  cert_email: \"youremail@gmail.com\"}])\n\nYou can then read the password of the grafana using this command: vm.sshable.cmd(\"sudo cat /etc/grafana/grafana.ini | grep admin_password\")",
    "ellipsis_summary": "Add strands for Grafana and Node Exporter setup, integrate metrics configuration in VM host lifecycle, and update tests.\n> \n>   - **Behavior**:\n>     - Adds `SetupGrafana` strand in `prog/setup_grafana.rb` to install Grafana on a VM, handling domain and certificate email.\n>     - Adds `SetupNodeExporter` strand in `prog/setup_node_exporter.rb` to install Node Exporter version 1.9.1.\n>     - Integrates metrics configuration in `prog/vm/host_nexus.rb` with a new `configure_metrics` label.\n>   - **Scripts**:\n>     - Adds `setup-grafana` script in `rhizome/host/bin/setup-grafana` for installing Grafana, configuring Nginx, and setting up SSL.\n>     - Adds `setup-node-exporter` script in `rhizome/host/bin/setup-node-exporter` for installing Node Exporter and configuring it as a service.\n>   - **Models**:\n>     - Updates `VmHost` in `model/vm_host.rb` to include metrics configuration and session initialization for metrics export.\n>   - **Tests**:\n>     - Adds tests for `SetupGrafana` in `spec/prog/setup_grafana_spec.rb`.\n>     - Adds tests for `SetupNodeExporter` in `spec/prog/setup_node_exporter_spec.rb`.\n>     - Updates `VmHost` tests in `spec/model/vm_host_spec.rb` to cover metrics configuration.\n>     - Updates `HostNexus` tests in `spec/prog/vm/host_nexus_spec.rb` to cover new metrics configuration behavior.\n> \n>"
  },
  {
    "pr": 3438,
    "title": "Optimize VmHost#ip4_random_vm_network",
    "description": "This allows VmHost#ip4_random_vm_network to use a single query instead of potentially recursive method calls with N+1 queries.\n\nThe first step is populating a table with all valid IPv4 addresses for VMs running on the host. This adds a `ipv4_address` table, and has newly created `Address` instances populate the table if the address is IPv4 and not for a single IP.\n\nWith the table populated, VmHost#ip4_random_vm_network only needs to take the universe of available addresses, remove the assigned addresses, and pick a random remaining address.\n\nThis currently emits and falls back to the previous implementation if the `ipv4_address` has not been populated for the host.  We can remove the fallback after some time if we do not see any production issues, this is just me being cautious.\n\nThis depends on #3437, which adds better NetAddr/Sequel integration.",
    "ellipsis_summary": "Optimize `VmHost#ip4_random_vm_network` using a new `ipv4_address` table to reduce queries and improve performance.\n> \n>   - **Behavior**:\n>     - Optimize `VmHost#ip4_random_vm_network` to use a single query with `ipv4_address` table instead of recursive calls.\n>     - Falls back to old implementation if `ipv4_address` table is not populated.\n>   - **Database**:\n>     - Add migration `20250610_ipv4_address.rb` to create `ipv4_address` table with constraints for IPv4 addresses.\n>   - **Models**:\n>     - `Address` model: Add `populate_ipv4_addresses` to populate `ipv4_address` table on creation.\n>     - `VmHost` model: Modify `ip4_random_vm_network` to use `ipv4_address` table.\n>   - **Tests**:\n>     - Add tests in `address_spec.rb` for `populate_ipv4_addresses`.\n>     - Add tests in `vm_host_spec.rb` for `ip4_random_vm_network` using `ipv4_address` table.\n> \n>"
  },
  {
    "pr": 3446,
    "title": "Postgres UI Revamp",
    "description": "As we add more and more features for PostgreSQL, it become difficult to navigate. So we decided to split the features into multiple pages. This PR does those splitting along with some clean up work. All tests are fixed as a separate commit, which is something I don't want to do usually. I prefer every commit to pass tests, however it was difficult to do that for such big refactoring.\n\nHere are some notable pages:\n|Overview    | Connections | Backups\n| -------- | ------- |------- |\n| ![Overview](https://github.com/user-attachments/assets/ba9e4d10-509d-40a0-8e2d-eebc08e93fa9) | ![Connection](https://github.com/user-attachments/assets/8e791008-7881-4195-92ec-a4344b67fbf3) | ![Backups](https://github.com/user-attachments/assets/90d77bfc-5aa1-4543-bee0-aa1e2c956deb) |",
    "ellipsis_summary": "Revamps PostgreSQL UI by splitting features into multiple pages, updating routes, and enhancing components for improved navigation and user experience.\n> \n>   - **UI Revamp**:\n>     - Splits PostgreSQL features into multiple pages: `overview`, `connection`, `charts`, `networking`, `resize`, `high-availability`, `read-replica`, `backup-restore`, `settings`.\n>     - Updates `show.erb` to render pages dynamically based on the selected submenu.\n>     - Adds new components like `icon_with_text.erb` for better UI representation.\n>   - **Routing and Redirection**:\n>     - Updates routes in `postgres.rb` to redirect to specific pages like `/overview`, `/settings`, etc.\n>     - Adjusts redirection logic for actions like `delete`, `promote`, `reset-superuser-password`.\n>   - **JavaScript and CSS**:\n>     - Adds animations in `tailwind.config.js` for UI elements.\n>     - Implements JavaScript for dynamic content updates in `app.js`.\n>   - **Testing**:\n>     - Updates tests in `postgres_spec.rb` to align with new page structure and functionalities.\n>     - Ensures tests cover new navigation and feature access scenarios.\n>   - **Miscellaneous**:\n>     - Changes `channel_binding=require` to `sslmode=require` in connection strings across multiple files.\n>     - Refactors components like `copyable_content.erb` and `revealable_content.erb` for enhanced functionality.\n> \n>"
  },
  {
    "pr": 3449,
    "title": "Use Ubiblk for volumes if installed on the host.",
    "description": "If any Ubiblk installations are enabled on a VmHost, the allocator will choose one at random, weighted by `allocation_weight`. Otherwise, SPDK will be used.\n\nCurrently, Ubiblk is not installed by default and must be set up manually by an operator. Therefore, the default behavior in production is to continue using SPDK.\n\nNote: The values for `num_queues` and `queue_size` are provisional and may change based on future performance and resource usage experiments.",
    "ellipsis_summary": "Introduce Ubiblk for volume allocation if available, defaulting to SPDK otherwise, with updates to models and allocation logic.\n> \n>   - **Behavior**:\n>     - If Ubiblk is installed on a `VmHost`, it is chosen randomly for volume allocation, weighted by `allocation_weight`. Otherwise, SPDK is used.\n>     - Default behavior remains SPDK unless Ubiblk is manually installed.\n>     - `num_queues` and `queue_size` are set provisionally in `vm.rb` and `vm_storage_volume.rb`.\n>   - **Models**:\n>     - `Vm` and `VmStorageVolume` updated to include `vhost_block_backend_version`, `num_queues`, and `queue_size`.\n>     - `VmStorageVolume` methods `num_queues` and `queue_size` return different values based on backend type.\n>   - **Allocator**:\n>     - `allocate_vhost_block_backend` method added to `allocator.rb` for selecting Ubiblk backends.\n>     - `create_storage_volumes` in `allocator.rb` updated to choose between Ubiblk and SPDK.\n>   - **Tests**:\n>     - Tests in `vm_spec.rb`, `vm_storage_volume_spec.rb`, and `allocator_spec.rb` updated to cover new allocation logic and backend selection.\n> \n>"
  },
  {
    "pr": 3459,
    "title": "Dispatcher improvements and additional metrics",
    "description": "Additional metrics:\n\n* total_delay : Combines the scan delay, queue delay, and lease delay into a single number.  This should be the main metric we look at to determine overall respirate performance.\n\n* old_strand_percentage: Percentage of strands processed that were outside of the process's current partition. Along with lease acquire_percentage, this is useful for determining how the partitioning is working.  The ideal percentage is 0%.\n\nImprovements:\n\n* Consider strand delay for current process when determining which strands outside the partition to scan for.  This calculates the p95 of the total delay for the processing of the current partition's strands, adds 20% and and additional 5 seconds.  This should fix issues we have in production when the respirate processes get overloaded, as the lease acquired percentage can drop from 100% to around 80% in that case.\n\n* Don't convert the strands/second metric to integer, as the float number provides more accurate information.",
    "ellipsis_summary": "Add new metrics and improve dispatcher logic to handle strand delays and partitioning more effectively.\n> \n>   - **Metrics**:\n>     - Add `total_delay` metric in `strand.rb` to combine scan, queue, and lease delays.\n>     - Add `old_strand_percentage` metric in `dispatcher.rb` to track strands processed outside the current partition.\n>   - **Improvements**:\n>     - Modify `scan_old` in `dispatcher.rb` to consider `old_strand_delay` before processing strands outside the partition.\n>     - Update `metrics_hash` in `dispatcher.rb` to calculate `@current_strand_delay` using p95 of `total_delay`.\n>     - Change `strands_per_second` to float in `dispatcher.rb` for accuracy.\n>   - **Tests**:\n>     - Update `dispatcher_spec.rb` to test new metrics and behavior changes, including `scan_old` and `metrics_hash`.\n> \n>"
  },
  {
    "pr": 3460,
    "title": "Update timeout-minutes from 15 to 25",
    "description": "The arm CI can take close to 7 minutes for one run, and it runs twice, once in coverage mode and once in frozen mode.  Killing it at 15 minutes is probably a false positive. Increase to 25 minutes.",
    "ellipsis_summary": "Increase `timeout-minutes` from 15 to 25 in `.github/workflows/ci.yml` to prevent premature timeouts for ARM CI jobs.\n> \n>   - **CI Configuration**:\n>     - Update `timeout-minutes` from 15 to 25 in `.github/workflows/ci.yml` to accommodate longer ARM CI job durations.\n> \n>"
  },
  {
    "pr": 3462,
    "title": "Simplify Options Usage for PostgreSQL (SOUP)",
    "description": "The option.rb file for PostgreSQL (and other products) has become increasingly difficult to maintain over time. We've followed various approaches throughout its evolution, and as more features were added, those approaches began to overlap and resulted in a tangled mess of spaghetti code.\n\nThis PR aims to clean things up by:\n- Keeping only globally valid options in option.rb and removing all embedded business logic.\n- Moving the business logic into generate_postgres_options, where it was originally intended to reside.\n- Leveraging the option tree for validations, eliminating the need for separate validation functions for each parameter.",
    "ellipsis_summary": "Centralizes PostgreSQL option handling and validation in `generate_postgres_options`, improving maintainability and reducing redundancy.\n> \n>   - **Behavior**:\n>     - Centralizes PostgreSQL option business logic in `generate_postgres_options`.\n>     - Uses option tree for validations, removing redundant validation functions.\n>   - **Code Changes**:\n>     - Updates `postgres_post` in `postgres.rb` to use centralized option handling.\n>     - Refactors `generate_postgres_options` to include all business logic and validations.\n>     - Removes specific validation functions from `validation.rb`.\n>   - **Misc**:\n>     - Updates CLI commands and tests to reflect new option handling.\n>     - Renames and restructures option constants in `option.rb` for clarity.\n> \n>"
  },
  {
    "pr": 3463,
    "title": "Make cache entry clean up more explicit while destroying a repository",
    "description": "We should only call `repository.destroy` from nexus prog, since it has a\nstrand. So no need to keep destroy logic in the model, we can move it to\nthe prog similar to PG timeline.\n\nAlso we remove cache entries explicitly. Previously, we are expecting\nthe association_dependencies in the model to handle this. But we just\nneed to be sure that the all caches are cleared before destroy the blob\nstorage bucket. Making this explicit in the prog makes it clearer.",
    "ellipsis_summary": "Refactor repository destruction to explicitly handle cache cleanup and blob storage deletion in `GithubRepositoryNexus` program.\n> \n>   - **Behavior**:\n>     - Moves cache entry cleanup and blob storage destruction from `GithubRepository` model to `GithubRepositoryNexus` program.\n>     - Ensures cache entries are destroyed before blob storage in `destroy` method of `GithubRepositoryNexus`.\n>   - **Model Changes**:\n>     - Removes `after_destroy` callback from `GithubRepository`.\n>     - `destroy_blob_storage` now explicitly aborts multipart uploads before deleting the bucket.\n>   - **Program Changes**:\n>     - Adds cache entry cleanup and blob storage destruction to `destroy` method in `GithubRepositoryNexus`.\n>   - **Tests**:\n>     - Updates `github_repository_spec.rb` to remove tests for `after_destroy`.\n>     - Adds tests in `github_repository_nexus_spec.rb` for new destruction logic.\n> \n>"
  },
  {
    "pr": 3465,
    "title": "Use NUL delimiter for xargs in github actions",
    "description": "Some `encoded_jit_config` values can interact badly with `xargs`'s quoting rules, which are not of that of the shell, but of xargs's own, similar design (see the first few paragraphs of the manual page)\n\nIn 29cbec28c, I packed the token in `xargs` to avoid it being emitted in our log telemetry, as we don't save stdin, because we customarily use it for secrets.\n\nBecause we're only packing a single value for a single invocation of the subcommand, we can use the NUL byte delimitation mode of `xargs` to evade its own interpretation of spaces and quotes, so long as `encoded_jit_config` is not binary. That no NUL byte appears in stdin is fine: the end-of-file condition when emitting the token is enough.",
    "ellipsis_summary": "Change `xargs` command in `github_runner.rb` to use NUL byte delimiter for robust handling of `encoded_jit_config`.\n> \n>   - **Behavior**:\n>     - Change `xargs` command in `github_runner.rb` to use `-0` option for NUL byte delimiter, ensuring robust handling of `encoded_jit_config`.\n>   - **Tests**:\n>     - Update test in `github_runner_spec.rb` to expect `xargs -0I{}` command format.\n> \n>"
  },
  {
    "pr": 3467,
    "title": "Split VM creation page into GPU/non-GPU if get_ff_gpu_vm feature flag is set",
    "description": "This can potentially make it easier to select a GPU instance.\n\nWith the feature flag set, instead of one button link to the create page, there are two:\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm](https://github.com/user-attachments/assets/cf5066a7-21be-44d5-abad-3412d0fb880d)\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm (1)](https://github.com/user-attachments/assets/74524ab4-92ed-4661-bb35-74fd8ee5224f)\n\nThe \"Create Virtual Machine\" link does not show any GPU options:\n\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm_create_gpu=f](https://github.com/user-attachments/assets/51cc699f-89ab-4d04-b471-e31084aa0061)\n\nThe \"Create GPU Virtual Machine\" only shows valid options for a GPU configuration:\n\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm_create_gpu=true](https://github.com/user-attachments/assets/0916c29a-89db-4959-b1ad-457e577eda3c)\n\nIf users have a direct link to the old page, it works the same as before, showing both GPU and non GPU options:\n\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm_create](https://github.com/user-attachments/assets/e9c40536-96cc-4804-9588-912477086070)\n\nIgnore the fact that the screenshots show the GPU VM in Finland.  My test host is in Finland, and I had to add billing rates to get things to work in development.\n\nRequested by @umurc",
    "ellipsis_summary": "Split VM creation page into GPU and non-GPU options based on feature flag, with UI updates and tests.\n> \n>   - **Behavior**:\n>     - Split VM creation page into GPU and non-GPU options if `get_ff_gpu_vm` feature flag is set.\n>     - `generate_vm_options` in `helpers/vm.rb` now considers `@show_gpu` to filter GPU options.\n>     - Redirects to error if no GPU VMs are available when `show_gpu` is true.\n>   - **UI Changes**:\n>     - `views/vm/index.erb` and `views/vm/create.erb` updated to show separate buttons for \"Create Virtual Machine\" and \"Create GPU Virtual Machine\" based on feature flag.\n>     - `views/components/empty_state.erb` supports multiple buttons.\n>   - **Tests**:\n>     - Added tests in `spec/routes/web/vm_spec.rb` to verify GPU and non-GPU VM creation paths and error handling.\n> \n>"
  },
  {
    "pr": 3468,
    "title": "Remove sampling strands for metrics",
    "description": "The new respirate provides much more accurate metrics, so it's not worth keeping these sampled metrics.",
    "ellipsis_summary": "Remove verbose logging for sampling strands in `strand.rb` and related tests in `strand_spec.rb`.\n> \n>   - **Behavior**:\n>     - Removes verbose logging logic in `strand.rb` for sampling strands, which was based on a random condition.\n>     - Deletes related tests in `strand_spec.rb` that checked for verbose logging behavior.\n>   - **Misc**:\n>     - Removes `verbose_logging` method and its conditional logic in `strand.rb`.\n>     - Deletes tests for verbose logging in `strand_spec.rb`.\n> \n>"
  },
  {
    "pr": 3469,
    "title": "Handle Octokit::NotFound for runner recycle",
    "description": "- **Remove the unused GCR mirror setup**\n  We have already moved the GCR mirror setup to image generation at\n  https://github.com/ubicloud/runner-images/pull/16\n  \n  There's no need to do it here again.\n  \n\n- **Handle Octokit::NotFound for deleted runners during recycle condition check**\n  When deciding to recycle a runner, we query the GitHub API to ensure\n  it’s not currently running a job, protects against delayed webhook\n  events. If the runner has already been deleted, the API raises\n  `Octokit::NotFound`. This case should be handled similarly to the\n  destroy label logic, where we also verify if the runner is busy.\n  \n  This commit moves the busy-check logic into a separate method to handle\n  both scenarios consistently.\n  \n\n- **Add deadline for recycling runners**\n  In rare cases, a runner marked for recycling may get stuck due to GitHub\n  API errors, and we lose visibility into its state. We've seen a few\n  instances of long-running, stuck runners in production.\n  \n  This change adds a 2-hour deadline to the recycling process so we can\n  detect and alert on such cases. While recycling typically completes\n  within a minute, the runner might be busy and delay recycling, so the\n  deadline is intentionally generous to avoid false positives, aligning\n  with the existing 2-hour deadline used for the destroy label.\n  \n\n- **Register deadline for runner in wait state**\n  GitHub allows self-hosted runners to stay active for up to 5 days. So we\n  shouldn't have any runner in the \"wait\" state beyond that limit.\n  \n  https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners/usage-limits-for-self-hosted-runners\n  \n  This change adds a safety check by registering a 5-day deadline for\n  runners in the wait state. With this, all labels in the runner prog\n  now have associated deadlines to help detect and recover from stuck\n  states.",
    "ellipsis_summary": "Handle `Octokit::NotFound` for runner recycling, add deadlines for recycling and wait states, and remove unused GCR mirror setup.\n> \n>   - **Behavior**:\n>     - Handle `Octokit::NotFound` in `busy?` method in `github_runner.rb` to manage deleted runners during recycle checks.\n>     - Add 2-hour deadline for recycling runners in `wait` method to detect stuck runners.\n>     - Register 5-day deadline for runners in \"wait\" state in `wait` method.\n>   - **Code Structure**:\n>     - Move busy-check logic to `busy?` method in `github_runner.rb` for consistent handling.\n>   - **Cleanup**:\n>     - Remove unused GCR mirror setup code from `setup_environment` in `github_runner.rb`.\n>   - **Tests**:\n>     - Add test for handling `Octokit::NotFound` in `wait` method in `github_runner_spec.rb`.\n> \n>"
  },
  {
    "pr": 3470,
    "title": "Check active session before the root route",
    "description": "Fixes issue if the session has an account id, but the account has been closed, as closing the account deletes all active sessions.\n\nTo be extra sure to avoid the error, also check current_account instead of rodauth.logged_in? in the root route.",
    "ellipsis_summary": "Move `rodauth.check_active_session` before root route logic in `clover.rb` to ensure session is active and replace `rodauth.logged_in?` with `current_account` check.\n> \n>   - **Behavior**:\n>     - Move `rodauth.check_active_session` before root route logic in `clover.rb` to ensure session is active before checking `current_account`.\n>     - Fixes issue where closed accounts (which delete sessions) could cause errors if session has an account id.\n>   - **Logic**:\n>     - Replace `rodauth.logged_in?` with `current_account` check in root route to ensure account is valid and active.\n> \n>"
  },
  {
    "pr": 3473,
    "title": "Allow 100GB of free cache storage if premium runners are enabled",
    "description": "",
    "ellipsis_summary": "> [!IMPORTANT]\n> Add `cache_storage_gib` method to `GithubInstallation` for cache storage limits, update cache handling and display logic, and add tests.\n> \n>   - **Behavior**:\n>     - Adds `cache_storage_gib` method in `GithubInstallation` to return 100GB if premium runners are enabled, otherwise returns effective quota.\n>     - Updates cache cleanup logic in `cleanup_cache` in `github_repository_nexus.rb` to use `cache_storage_gib` for storage limit.\n>     - Modifies cache quota display in `github.rb` to use `cache_storage_gib`.\n>   - **Tests**:\n>     - Adds tests for `cache_storage_gib` in `github_installation_spec.rb` to verify behavior with and without premium runners.\n> \n>"
  },
  {
    "pr": 3476,
    "title": "Add dump_sequel_caches rake task",
    "description": "This converts the marshalled cache file to a text based file. The reason to have this is it allows you to debug changes in cache files.  If you are rebasing a commit and there is a conflict in a cache file, you can run this before the commit, run this after the commit, and then `diff -ru` the two directories, to see what actually changed in the cache.",
    "ellipsis_summary": "Adds `dump_sequel_caches` task to `Rakefile` to convert marshalled cache files to text format for easier debugging and diffing.\n> \n>   - **New Task**:\n>     - Adds `dump_sequel_caches` task to `Rakefile` to convert marshalled cache files to text format.\n>     - Handles `schema`, `index`, `static_cache`, and `pg_auto_constraint_validations` cache types.\n>     - Outputs text files to a timestamped directory for easy diffing.\n>   - **Misc**:\n>     - Updates description of `refresh_sequel_caches` task in `Rakefile`.\n> \n>"
  },
  {
    "pr": 3477,
    "title": "Don't use cached children in `donate`.",
    "description": "E2E tests failed because a `Test::Prog::Vm`'s strand went back from `ping_google` to `verify_extra_disks`. `Test::Prog::Vm` is run in two ways: Either by the scheduler or by a call to `donate` in `Prog::Test::VmGroup.wait_verify_vms`.\r\n\r\nWe suspect that the issue we saw might be because of caching in `donate`, so this is a try to fix that issue.",
    "ellipsis_summary": "----\r\n\r\n> [!IMPORTANT]\r\n> Modify `donate` method to use `children_dataset` for up-to-date child labels and update tests accordingly.\r\n> \r\n>   - **Behavior**:\r\n>     - Modify `donate` method in `prog/base.rb` to use `strand.children_dataset` instead of `strand.children` to ensure up-to-date child labels.\r\n>   - **Tests**:\r\n>     - Update `install_dnsmasq_spec.rb` to mock `strand.children_dataset` in `donate` test.\r\n>     - Update `provision_kubernetes_node_spec.rb` to mock `strand.children_dataset` in `donate` test.\r\n>     - Update `upgrade_kubernetes_node_spec.rb` to mock `strand.children_dataset` in `donate` test.\r\n> \r\n>"
  },
  {
    "pr": 3478,
    "title": "Move GPU option above server size option on Create GPU Virtual Machine page",
    "description": "You cannot put it above server family option, because the content generation code does not allow an option to be rendered before options it depends on.\n\n![localhost_3000_project_pjkvsq7s5e5a7mjtsdjvetweyk_vm_create_show_gpu=t](https://github.com/user-attachments/assets/275d1266-5ab2-42e9-bc7d-7ec2e58fc8b1)\n\nRequested by @umurc",
    "ellipsis_summary": "Reorder GPU option above server size option on Create GPU Virtual Machine page in `views/vm/create.erb`.\n> \n>   - **Behavior**:\n>     - Move GPU option above server size option in `views/vm/create.erb`.\n>     - GPU option cannot be moved above server family option due to dependency constraints.\n>   - **Implementation**:\n>     - Modify `elements` array to conditionally prepend GPU option if `@show_gpu` is true.\n>     - Concatenate `elements` with `form_elements` to reflect new order.\n> \n>"
  },
  {
    "pr": 3479,
    "title": "Clear cached instance state in Strand#take_lease_and_reload",
    "description": "This avoids the use of instance_variable_delete, as that doesn't play well with object shapes.  Internal code should always call the subject method, and not access `@subject` directly.",
    "ellipsis_summary": "In `Strand#take_lease_and_reload`, set `@subject` to `:reload` to clear cached instance state, ensuring `subject` reloads after lease, with tests verifying this behavior.\n> \n>   - **Behavior**:\n>     - In `Strand#take_lease_and_reload`, set `@subject` to `:reload` to clear cached instance state, ensuring `subject` reloads after lease.\n>     - Avoids `instance_variable_delete` for better object shape handling.\n>   - **Tests**:\n>     - Add test in `strand_spec.rb` to verify cached instance state is cleared and reloaded in `take_lease_and_reload`.\n> \n>"
  },
  {
    "pr": 3480,
    "title": "Make Service URL of k8s clusters copy-able",
    "description": "I find myself doing a lof of copy-paste for the service URL, so why not make it easier to copy.",
    "ellipsis_summary": "Add `{ copyable: true }` to Service URL in `show.erb` for easier copying when Kubernetes cluster is running.\n> \n>   - **Behavior**:\n>     - Adds `{ copyable: true }` to the Service URL in `show.erb` for Kubernetes clusters, making it easier to copy when the cluster is running.\n> \n>"
  },
  {
    "pr": 3481,
    "title": "Revert the use of the ipv4_address table to speed up VmHost#ip4_random_vm_network",
    "description": "Revert \"Use NOT EXISTS instead of NOT IN in VmHost#ip4_random_vm_network\"\n\nThis reverts commit 5f47eedc33309b771de81844ac14ab7a8c3f6342.\n\nRevert \"Update/remove no longer accurate comments\"\n\nThis reverts commit 6c17867cec48b051e5792b005e52d26db9dc3f7d.\n\nRevert \"Use early return in Address#populate_ipv4_addresses\"\n\nThis reverts commit f1f720ecfb0f2d395f79fb6cb8775fb7df00ec95.\n\nRevert \"Use described_class.new_with_id in VmHost specs\"\n\nThis reverts commit fa9e0b5a3c860e328185c2931672d8a78a2c3a41.\n\nRevert \"Use ipv4_address table to speed up VmHost#ip4_random_vm_network\"\n\nThis reverts commit e8c2945c9d90292a8cab477f1763fb3e2407dcdb.",
    "ellipsis_summary": "Reverts changes to `VmHost#ip4_random_vm_network` and `Address#populate_ipv4_addresses`, removing `ipv4_address` table usage.\n> \n>   - **Behavior**:\n>     - Reverts `VmHost#ip4_random_vm_network` to previous logic, removing use of `ipv4_address` table.\n>     - Reverts `Address#populate_ipv4_addresses` to previous logic, removing early return.\n>   - **Associations**:\n>     - Removes `assigned_vm_addresses` association from `VmHost`.\n>   - **Tests**:\n>     - Reverts tests in `vm_host_spec.rb` related to `ipv4_address` table population and usage.\n>     - Removes tests for `ip4_random_vm_network` using `ipv4_address` table.\n>   - **Misc**:\n>     - Reverts comments in `address.rb` and `vm_host.rb` to previous state.\n> \n>"
  },
  {
    "pr": 3483,
    "title": "Fix ipv4_address table population in Address#populate_ipv4_addresses",
    "description": "Change\n\nid != routed_to_host_id\n\nto\n\nvm_host.sshable.host != cidr.network.to_s\n\nWe do not consistently use the VmHost id as the primary Address id (it is not done at all for Hetzner hosts), so the next simplest way to check is check the sshable address.\n\nExisting installations that previously ran\nAddress#populate_ipv4_addresses can be fixed using:\n\nDB[:ipv4_address].where(ip: Sshable.where(id: VmHost.select(:id)).select(Sequel.cast(:host, :inet))).delete",
    "ellipsis_summary": "Fix `populate_ipv4_addresses` in `address.rb` to exclude host's sshable IP address and add corresponding test.\n> \n>   - **Behavior**:\n>     - In `address.rb`, `populate_ipv4_addresses` now excludes the host's sshable IP address by comparing `vm_host.sshable.host` with `cidr.network.to_s`.\n>     - Existing installations can be fixed with a provided SQL command to delete incorrect entries.\n>   - **Tests**:\n>     - Added test in `address_spec.rb` to ensure the host's sshable IP address is not populated in `ipv4_address` table.\n> \n>"
  },
  {
    "pr": 3484,
    "title": "Revert \"Revert the use of the ipv4_address table to speed up VmHost#ip4_random_vm_network\"",
    "description": "This reverts commit e95a6bcc9982261b69ee20cfe0145f63f294fa05.\n\nThis includes a conflict fix for the previous commit.",
    "ellipsis_summary": "Reverts previous commit to restore `ipv4_address` table usage in `VmHost#ip4_random_vm_network`, optimizing IP allocation logic and updating tests.\n> \n>   - **Behavior**:\n>     - Reverts previous commit to restore use of `ipv4_address` table in `VmHost#ip4_random_vm_network`.\n>     - Adjusts logic in `populate_ipv4_addresses` in `address.rb` to handle IPv4 addresses correctly.\n>     - Updates `ip4_random_vm_network` in `vm_host.rb` to use `ipv4_address` table for faster IP allocation.\n>   - **Tests**:\n>     - Updates tests in `vm_host_spec.rb` to reflect changes in IP allocation logic.\n>     - Adds test cases for scenarios when `ipv4_address` table is populated and when it is not.\n> \n>"
  },
  {
    "pr": 3490,
    "title": "Make `SpdkSetup.prep` idempotent in Ubuntu 24.04.",
    "description": "This function was intended to be idempotent. In Ubuntu 22.04, when the `spdk` user already existed, we got the following error:\n\n```\nWarning: The home dir /home/spdk you specified already exists.\nadduser: The user `spdk' already exists.\n```\n\nIn Ubuntu 24.04, this has changed to:\n\n```\ninfo: The home dir /home/spdk you specified already exists.\n\nfatal: The user `spdk' already exists.\n```\n\nThis PR changes the regex to catch both cases.",
    "ellipsis_summary": "Update `SpdkSetup.prep` to handle user existence errors in Ubuntu 22.04 and 24.04 by modifying regex and adding tests.\n> \n>   - **Behavior**:\n>     - Update `SpdkSetup.prep` in `spdk_setup.rb` to handle user existence error messages for both Ubuntu 22.04 and 24.04.\n>     - Modify regex to match both \"adduser: The user `spdk' already exists.\" and \"fatal: The user `spdk' already exists.\".\n>   - **Tests**:\n>     - Add test for Ubuntu 24.04 user existence case in `spdk_setup_spec.rb`.\n>     - Ensure existing test for Ubuntu 22.04 user existence case remains valid.\n> \n>"
  },
  {
    "pr": 3500,
    "title": "Fix CA certificate download button",
    "description": "Connection information is now served from its own subpage, so `request.path` is not the correct way to generate the API endpoint.",
    "ellipsis_summary": "----\r\n\r\n> [!IMPORTANT]\r\n> Fixes CA certificate download link in `views/postgres/connection.erb` by using `@project_data[:path]` and `@pg.path` instead of `request.path`.\r\n> \r\n>   - **Fix**:\r\n>     - Corrects CA certificate download link in `views/postgres/connection.erb` by using `@project_data[:path]` and `@pg.path` instead of `request.path`.\r\n>     - Ensures correct API endpoint generation for CA certificate download.\r\n> \r\n>"
  }
]